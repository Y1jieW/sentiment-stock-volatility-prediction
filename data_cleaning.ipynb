{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b52afb1",
   "metadata": {},
   "source": [
    "#2025年truth文本数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db87b770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/wangyijie/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/wangyijie/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cff8a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  web-scraper-order                              web-scraper-start-url  \\\n",
      "0     1753354145-67  https://rollcall.com/factbase/trump/topic/soci...   \n",
      "1     1753354145-68  https://rollcall.com/factbase/trump/topic/soci...   \n",
      "2     1753354145-69  https://rollcall.com/factbase/trump/topic/soci...   \n",
      "3     1753354145-70  https://rollcall.com/factbase/trump/topic/soci...   \n",
      "4     1753354145-71  https://rollcall.com/factbase/trump/topic/soci...   \n",
      "\n",
      "                         date  \\\n",
      "0  July 20, 2025 @ 8:53 PM ET   \n",
      "1  July 20, 2025 @ 8:16 PM ET   \n",
      "2  July 20, 2025 @ 8:06 PM ET   \n",
      "3  July 20, 2025 @ 8:06 PM ET   \n",
      "4  July 20, 2025 @ 7:56 PM ET   \n",
      "\n",
      "                                                text  \n",
      "0  Adam “Shifty” Schiff is in BIG TROUBLE! He fal...  \n",
      "1  RT: https://truthsocial.com/users/realDonaldTr...  \n",
      "2  Go get the GREAT NEW BOOK by Mark Levin. It’s ...  \n",
      "3  RT: https://truthsocial.com/users/realDonaldTr...  \n",
      "4   HOW DID SAMANTHA POWER MAKE ALL OF THAT MONEY???  \n"
     ]
    }
   ],
   "source": [
    "# === 1. 加载合并后的文本数据 ===\n",
    "input_file = \"01文本抓取与预处理/2025_truth.csv\"\n",
    "df = pd.read_csv(input_file)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55ad466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 保留重要字段\n",
    "df = df[['date', 'text']].dropna()\n",
    "# 3. 转换日期格式\n",
    "def parse_date(raw_date):\n",
    "    try:\n",
    "        return datetime.strptime(raw_date.replace('ET', '').strip(), '%B %d, %Y @ %I:%M %p')\n",
    "    except:\n",
    "        return pd.NaT\n",
    "\n",
    "df['date'] = df['date'].apply(parse_date)\n",
    "df = df.dropna(subset=['date'])\n",
    "\n",
    "# 4. 基础清洗函数\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)  # 去除 URL\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)            # 去用户名（如有）\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)            # 去话题标签\n",
    "    #text = re.sub(r\"\\brt\\b\", \"\", text, flags=re.IGNORECASE)  # 删除“rt”（忽略大小写）\n",
    "    text = re.sub(r\"\\n\", \" \", text)             # 换行符换成空格\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()    # 多空格压缩\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# 5. 可选：小写 + 去标点 + 去停用词 + 词形还原\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def normalize(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['clean_text'] = df['clean_text'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8dc7d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除clean_text列中是空值或仅包含空白的行\n",
    "df = df[df['clean_text'].notna() & (df['clean_text'].str.strip() != '')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7aa36c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # 表情符号\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # 符号&象形文字\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # 交通工具&地图符号\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # 国旗\n",
    "        u\"\\U00002700-\\U000027BF\"  # 杂项符号\n",
    "        u\"\\U0001F900-\\U0001F9FF\"  # 补充表情符号\n",
    "        u\"\\U00002600-\\U000026FF\"  # 杂项符号\n",
    "        u\"\\U0001FA70-\\U0001FAFF\"  # 补充符号和象形文字\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# 应用到 clean_text 字段\n",
    "df['clean_text'] = df['clean_text'].apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "61605dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['clean_text'].str.replace(r'\\brt\\b', '', case=False, regex=True)\n",
    "df['clean_text'] = df['clean_text'].str.replace(r'\\s+', ' ', regex=True).str.strip()  # 再次去空格\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "284abda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 保存清洗后的数据\n",
    "df[['date', 'clean_text']].to_csv(\"2025_truth_cleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec954a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ab78e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b5596b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99973b9c",
   "metadata": {},
   "source": [
    "# 第一届总统任期数据清洗预处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30de06d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    id                                               text  \\\n",
      "0    98454970654916608  Republicans and Democrats have both created ou...   \n",
      "1  1234653427789070336  I was thrilled to be back in the Great city of...   \n",
      "2  1218010753434820614  RT @CBS_Herridge: READ: Letter to surveillance...   \n",
      "3  1304875170860015617  The Unsolicited Mail In Ballot Scam is a major...   \n",
      "4  1218159531554897920  RT @MZHemingway: Very friendly telling of even...   \n",
      "\n",
      "  isRetweet isDeleted              device  favorites  retweets  \\\n",
      "0         f         f           TweetDeck         49       255   \n",
      "1         f         f  Twitter for iPhone      73748     17404   \n",
      "2         t         f  Twitter for iPhone          0      7396   \n",
      "3         f         f  Twitter for iPhone      80527     23502   \n",
      "4         t         f  Twitter for iPhone          0      9081   \n",
      "\n",
      "                  date isFlagged  \n",
      "0  2011-08-02 18:07:48         f  \n",
      "1  2020-03-03 01:34:50         f  \n",
      "2  2020-01-17 03:22:47         f  \n",
      "3  2020-09-12 20:10:58         f  \n",
      "4  2020-01-17 13:13:59         f  \n"
     ]
    }
   ],
   "source": [
    "input_file = \"/Users/wangyijie/Visual_Studio_code/毕业论文项目/01文本抓取与预处理/trump_第一任期.csv\"\n",
    "df_17 = pd.read_csv(input_file)\n",
    "print(df_17.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64ad5e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 保留重要字段\n",
    "df_17 = df_17[['date', 'text']].dropna()\n",
    "# 3. 转换日期格式\n",
    "df_17['date'] = pd.to_datetime(df_17['date'], errors='coerce')\n",
    "df_17 = df_17.dropna(subset=['date'])  # 删除无法解析为时间的行（如果有）\n",
    "\n",
    "# 4. 基础清洗函数\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)  # 去除 URL\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)            # 去用户名（如有）\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)            # 去话题标签\n",
    "    #text = re.sub(r\"\\brt\\b\", \"\", text, flags=re.IGNORECASE)  # 删除“rt”（忽略大小写）\n",
    "    text = re.sub(r\"\\n\", \" \", text)             # 换行符换成空格\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()    # 多空格压缩\n",
    "    text = re.sub(r'[\\u200e\\u200f\\u202a-\\u202e\\u2066-\\u2069]', '', text)        # 方向控制符\n",
    "    text = re.sub(r'[\\u2190-\\u21ff]', '', text)                                 # 箭头符号\n",
    "    text = text.replace('‼️', '')                                               # 特定emoji\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "df_17['clean_text'] = df_17['text'].apply(clean_text)\n",
    "\n",
    "# 5. 可选：小写 + 去标点 + 去停用词 + 词形还原\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def normalize(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = text.split()\n",
    "    words = [lemmatizer.lemmatize(w) for w in words if w not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df_17['clean_text'] = df_17['clean_text'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "367f19ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除clean_text列中是空值或仅包含空白的行\n",
    "df_17 = df_17[df_17['clean_text'].notna() & (df_17['clean_text'].str.strip() != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35695bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # 表情符号\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # 符号&象形文字\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # 交通工具&地图符号\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # 国旗\n",
    "        u\"\\U00002700-\\U000027BF\"  # 杂项符号\n",
    "        u\"\\U0001F900-\\U0001F9FF\"  # 补充表情符号\n",
    "        u\"\\U00002600-\\U000026FF\"  # 杂项符号\n",
    "        u\"\\U0001FA70-\\U0001FAFF\"  # 补充符号和象形文字\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# 应用到 clean_text 字段\n",
    "df_17['clean_text'] = df_17['clean_text'].apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f26758cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_17['clean_text'] = df_17['clean_text'].str.replace(r'\\brt\\b', '', case=False, regex=True)\n",
    "df_17['clean_text'] = df_17['clean_text'].str.replace(r'\\s+', ' ', regex=True).str.strip()  # 再次去空格\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fec57db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in /opt/anaconda3/lib/python3.12/site-packages (2.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install emoji\n",
    "import emoji\n",
    "\n",
    "# 删除所有 emoji，包括 ⬇️⬆️▶️🟥⏰‼️ 等\n",
    "df_17['clean_text'] = df_17['clean_text'].apply(lambda x: emoji.replace_emoji(x, replace=''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e88a1d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 保存清洗后的数据\n",
    "df_17[['date', 'clean_text']].to_csv(\"first_term_cleaned.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fce4bf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date                                         clean_text\n",
      "0  2011-08-02 18:07:48       republican democrat created economic problem\n",
      "1  2020-03-03 01:34:50  thrilled back great city charlotte north carol...\n",
      "2  2020-01-17 03:22:47  read letter surveillance court obtained cbs ne...\n",
      "3  2020-09-12 20:10:58  unsolicited mail ballot scam major threat demo...\n",
      "4  2020-01-17 13:13:59  friendly telling event comeys apparent leaking...\n"
     ]
    }
   ],
   "source": [
    "input_file = \"/Users/wangyijie/Visual_Studio_code/毕业论文项目/01文本抓取与预处理/first_term_cleaned.csv\"\n",
    "df_17_cleaned = pd.read_csv(input_file)\n",
    "print(df_17_cleaned.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3793e74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>2021-01-08 15:44:28</td>\n",
       "      <td>asked going inauguration january 20th</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>2021-01-08 14:46:38</td>\n",
       "      <td>75000000 great american patriot voted america ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>2021-01-06 23:01:04</td>\n",
       "      <td>thing event happen sacred landslide election v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>2021-01-06 20:13:26</td>\n",
       "      <td>asking everyone u capitol remain peaceful viol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>2021-01-06 19:38:58</td>\n",
       "      <td>please support capitol police law enforcement ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2021-01-06 19:24:22</td>\n",
       "      <td>mike penny didn’t courage done protect country...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>2021-01-06 15:44:31</td>\n",
       "      <td>scoundrel toying great guy vote didn’t want an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>2021-01-06 14:16:30</td>\n",
       "      <td>even mexico us voter id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>2021-01-06 14:15:07</td>\n",
       "      <td>state want redo vote found voted fraud legisla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2021-01-06 14:00:12</td>\n",
       "      <td>happened find 50000 ballot late last night usa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2021-01-06 13:22:26</td>\n",
       "      <td>republican party importantly country need pres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2021-01-06 13:17:22</td>\n",
       "      <td>state want correct vote know based irregularit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2021-01-06 13:06:45</td>\n",
       "      <td>sleepy eye chuck todd happy fake voter tabulat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2021-01-06 06:00:50</td>\n",
       "      <td>vice president come u win presidency many stat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2021-01-06 05:47:01</td>\n",
       "      <td>wow hear west wing—thank you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2021-01-06 05:46:29</td>\n",
       "      <td>pennsylvania going trump legislator spoken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2021-01-06 05:43:42</td>\n",
       "      <td>get smart republican fight</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2021-01-06 05:17:52</td>\n",
       "      <td>wonder water main gonna burst georgia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2021-01-06 05:17:43</td>\n",
       "      <td>democrat scrounging vote mystical place</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2021-01-06 05:16:10</td>\n",
       "      <td>steal making georgia wait</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date                                         clean_text\n",
       "272  2021-01-08 15:44:28              asked going inauguration january 20th\n",
       "269  2021-01-08 14:46:38  75000000 great american patriot voted america ...\n",
       "261  2021-01-06 23:01:04  thing event happen sacred landslide election v...\n",
       "252  2021-01-06 20:13:26  asking everyone u capitol remain peaceful viol...\n",
       "232  2021-01-06 19:38:58  please support capitol police law enforcement ...\n",
       "228  2021-01-06 19:24:22  mike penny didn’t courage done protect country...\n",
       "218  2021-01-06 15:44:31  scoundrel toying great guy vote didn’t want an...\n",
       "212  2021-01-06 14:16:30                            even mexico us voter id\n",
       "210  2021-01-06 14:15:07  state want redo vote found voted fraud legisla...\n",
       "200  2021-01-06 14:00:12  happened find 50000 ballot late last night usa...\n",
       "197  2021-01-06 13:22:26  republican party importantly country need pres...\n",
       "193  2021-01-06 13:17:22  state want correct vote know based irregularit...\n",
       "188  2021-01-06 13:06:45  sleepy eye chuck todd happy fake voter tabulat...\n",
       "185  2021-01-06 06:00:50  vice president come u win presidency many stat...\n",
       "178  2021-01-06 05:47:01                       wow hear west wing—thank you\n",
       "179  2021-01-06 05:46:29         pennsylvania going trump legislator spoken\n",
       "176  2021-01-06 05:43:42                         get smart republican fight\n",
       "172  2021-01-06 05:17:52              wonder water main gonna burst georgia\n",
       "173  2021-01-06 05:17:43            democrat scrounging vote mystical place\n",
       "163  2021-01-06 05:16:10                          steal making georgia wait"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_17_cleaned = df_17_cleaned.sort_values(by='date', ascending=False)\n",
    "df_17_cleaned.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8c37f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                   date                                         clean_text\n",
       " 272 2021-01-08 15:44:28              asked going inauguration january 20th\n",
       " 269 2021-01-08 14:46:38  75000000 great american patriot voted america ...\n",
       " 261 2021-01-06 23:01:04  thing event happen sacred landslide election v...\n",
       " 252 2021-01-06 20:13:26  asking everyone u capitol remain peaceful viol...\n",
       " 232 2021-01-06 19:38:58  please support capitol police law enforcement ...\n",
       " 228 2021-01-06 19:24:22  mike penny didn’t courage done protect country...\n",
       " 218 2021-01-06 15:44:31  scoundrel toying great guy vote didn’t want an...\n",
       " 212 2021-01-06 14:16:30                            even mexico us voter id\n",
       " 210 2021-01-06 14:15:07  state want redo vote found voted fraud legisla...\n",
       " 200 2021-01-06 14:00:12  happened find 50000 ballot late last night usa...,\n",
       "                      date                                         clean_text\n",
       " 44127 2017-01-20 17:55:44  follow two simple rule buy american amp hire a...\n",
       " 44128 2017-01-20 17:54:36  bring back job bring back border bring back we...\n",
       " 44129 2017-01-20 17:54:00  forgotten men woman country forgotten longer m...\n",
       " 44130 2017-01-20 17:53:17  january 20th 2017 remembered day people became...\n",
       " 44131 2017-01-20 17:52:45  truly matter party control government whether ...\n",
       " 44132 2017-01-20 17:51:58    power washington dc giving back american people\n",
       " 44133 2017-01-20 17:51:25  today merely transferring power one administra...\n",
       " 44134 2017-01-20 12:31:53  begin today see 1100 swearingin movement conti...\n",
       " 44135 2017-01-20 04:24:33              thank wonderful evening washington dc\n",
       " 44136 2017-01-20 00:40:51  thank joining u lincoln memorial tonight speci...)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 筛选2017年1月20日及以后的数据\n",
    "\n",
    "start_date = pd.to_datetime('2017-01-20')\n",
    "df_17_cleaned['date'] = pd.to_datetime(df_17_cleaned['date'], errors='coerce')\n",
    "df_17_filtered = df_17_cleaned[df_17_cleaned['date'] >= start_date]\n",
    "\n",
    "# 显示筛选后的数据,查看前10行和后10行\n",
    "df_17_filtered.head(10),  df_17_filtered.tail(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42195f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存为trump17_21.csv\n",
    "df_17_filtered.to_csv('trump17_21.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994abf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并为trump_merged_2017_2025.csv\n",
    "df_17_filtered = pd.read_csv('trump17_21.csv')\n",
    "df_25_cleaned = pd.read_csv('2025_truth_cleaned.csv')\n",
    "df_25_cleaned['date'] = pd.to_datetime(df_25_cleaned['date'], errors='coerce')\n",
    "df_17_filtered['date'] = pd.to_datetime(df_17_filtered['date'], errors='coerce')\n",
    "df_merged = pd.concat([df_17_filtered, df_25_cleaned], ignore_index=True)\n",
    "df_merged = df_merged.sort_values(by='date', ascending=False)\n",
    "df_merged.to_csv('trump_merged_2017_2025.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
